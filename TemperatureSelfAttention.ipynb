{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TemperatureSelfAttention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWxkeT1EKy6G0/UTPSuKZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLRG-CEFET-RJ/attention-mechanism/blob/main/TemperatureSelfAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K6mVmNS2IIu"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, zipfile, io\n",
        "from numpy import array\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import gc\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNIceLOZw8Lt"
      },
      "source": [
        "Baixar o arquivo com o conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d51q0jEW3FzC"
      },
      "source": [
        "zip_file_url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'\n",
        "\n",
        "r = requests.get(zip_file_url, stream=True)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBT49NJOxIaA"
      },
      "source": [
        "Carregar o arquivo (em formato CSV) para um objeto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_AA4hCM3eG9"
      },
      "source": [
        "df = pd.read_csv('jena_climate_2009_2016.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwjsIVBxWXJ"
      },
      "source": [
        "Visualização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "_rUGPc4E3hKW",
        "outputId": "df568256-b1f9-4fe3-ca69-0b563f22672c"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date Time</th>\n",
              "      <th>p (mbar)</th>\n",
              "      <th>T (degC)</th>\n",
              "      <th>Tpot (K)</th>\n",
              "      <th>Tdew (degC)</th>\n",
              "      <th>rh (%)</th>\n",
              "      <th>VPmax (mbar)</th>\n",
              "      <th>VPact (mbar)</th>\n",
              "      <th>VPdef (mbar)</th>\n",
              "      <th>sh (g/kg)</th>\n",
              "      <th>H2OC (mmol/mol)</th>\n",
              "      <th>rho (g/m**3)</th>\n",
              "      <th>wv (m/s)</th>\n",
              "      <th>max. wv (m/s)</th>\n",
              "      <th>wd (deg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01.01.2009 00:10:00</td>\n",
              "      <td>996.52</td>\n",
              "      <td>-8.02</td>\n",
              "      <td>265.40</td>\n",
              "      <td>-8.90</td>\n",
              "      <td>93.3</td>\n",
              "      <td>3.33</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.94</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1307.75</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.75</td>\n",
              "      <td>152.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01.01.2009 00:20:00</td>\n",
              "      <td>996.57</td>\n",
              "      <td>-8.41</td>\n",
              "      <td>265.01</td>\n",
              "      <td>-9.28</td>\n",
              "      <td>93.4</td>\n",
              "      <td>3.23</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.89</td>\n",
              "      <td>3.03</td>\n",
              "      <td>1309.80</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.50</td>\n",
              "      <td>136.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01.01.2009 00:30:00</td>\n",
              "      <td>996.53</td>\n",
              "      <td>-8.51</td>\n",
              "      <td>264.91</td>\n",
              "      <td>-9.31</td>\n",
              "      <td>93.9</td>\n",
              "      <td>3.21</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.88</td>\n",
              "      <td>3.02</td>\n",
              "      <td>1310.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.63</td>\n",
              "      <td>171.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01.01.2009 00:40:00</td>\n",
              "      <td>996.51</td>\n",
              "      <td>-8.31</td>\n",
              "      <td>265.12</td>\n",
              "      <td>-9.07</td>\n",
              "      <td>94.2</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.07</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.92</td>\n",
              "      <td>3.08</td>\n",
              "      <td>1309.19</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.50</td>\n",
              "      <td>198.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01.01.2009 00:50:00</td>\n",
              "      <td>996.51</td>\n",
              "      <td>-8.27</td>\n",
              "      <td>265.15</td>\n",
              "      <td>-9.04</td>\n",
              "      <td>94.1</td>\n",
              "      <td>3.27</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.92</td>\n",
              "      <td>3.09</td>\n",
              "      <td>1309.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.63</td>\n",
              "      <td>214.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date Time  p (mbar)  T (degC)  ...  wv (m/s)  max. wv (m/s)  wd (deg)\n",
              "0  01.01.2009 00:10:00    996.52     -8.02  ...      1.03           1.75     152.3\n",
              "1  01.01.2009 00:20:00    996.57     -8.41  ...      0.72           1.50     136.1\n",
              "2  01.01.2009 00:30:00    996.53     -8.51  ...      0.19           0.63     171.6\n",
              "3  01.01.2009 00:40:00    996.51     -8.31  ...      0.34           0.50     198.0\n",
              "4  01.01.2009 00:50:00    996.51     -8.27  ...      0.32           0.63     214.3\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxhP-fKGmwTQ"
      },
      "source": [
        "Preparação dos dados (converter a frequência de observações de 10 min para 1 hora)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2-UBKN04nfB",
        "outputId": "c59f718a-a395-4024-e490-f05bbe909dd5"
      },
      "source": [
        "print(df.shape)\n",
        "\n",
        "# slice [start:stop:step], starting from index 5, take every 6th record.\n",
        "df = df[5::6]\n",
        "\n",
        "print(df.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(420551, 15)\n",
            "(70091, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCLBLryn5jO9",
        "outputId": "17a7801e-3e58-4ca6-e91d-cb56e15fe03b"
      },
      "source": [
        "date_time = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
        "date_time"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5        2009-01-01 01:00:00\n",
              "11       2009-01-01 02:00:00\n",
              "17       2009-01-01 03:00:00\n",
              "23       2009-01-01 04:00:00\n",
              "29       2009-01-01 05:00:00\n",
              "                 ...        \n",
              "420521   2016-12-31 19:10:00\n",
              "420527   2016-12-31 20:10:00\n",
              "420533   2016-12-31 21:10:00\n",
              "420539   2016-12-31 22:10:00\n",
              "420545   2016-12-31 23:10:00\n",
              "Name: Date Time, Length: 70091, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskIulhJyp23"
      },
      "source": [
        "Sumário estatístico da temperatura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufK0R6hF5yXO",
        "outputId": "b36f0e0d-6dd8-4305-bb8c-b10164608870"
      },
      "source": [
        "temperature = df['T (degC)']\n",
        "temperature.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    70091.000000\n",
              "mean         9.450482\n",
              "std          8.423384\n",
              "min        -22.760000\n",
              "25%          3.350000\n",
              "50%          9.410000\n",
              "75%         15.480000\n",
              "max         37.280000\n",
              "Name: T (degC), dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyM8VVrT4P7h"
      },
      "source": [
        "Iremos usar 1200 exemplos para treinar o modelo e 500 exemplos, tanto para validação quanto para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Caz6XhVK6TS2",
        "outputId": "5c283a2e-b79e-43f8-ca38-6e2a9e4b1619"
      },
      "source": [
        "train_set = temperature[:1200]\n",
        "valid_set = temperature[69000:69500]\n",
        "test_set = temperature[69500:]\n",
        "print('Proporção de exemplos para treino: {:.2f}%'.format(len(train_set)/len(temperature)))\n",
        "print('Proporção de exemplos para validação: {:.2f}%'.format(len(valid_set)/len(temperature)))\n",
        "print('Proporção de exemplos para teste: {:.2f}%'.format(len(valid_set)/len(temperature)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporção de exemplos para treino: 0.02%\n",
            "Proporção de exemplos para validação: 0.01%\n",
            "Proporção de exemplos para teste: 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQRYhhZ453sk"
      },
      "source": [
        "Janelas deslizantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utTP5osP6j-u"
      },
      "source": [
        "def window_generator(sequence, n_steps):\n",
        "    x, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        \n",
        "        end_ix = i + n_steps\n",
        "        \n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        x.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(x), array(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za8BkrsW60Zk"
      },
      "source": [
        "n_steps = 3\n",
        "train_x, train_y = window_generator(train_set.values, n_steps)\n",
        "valid_x, valid_y = window_generator(valid_set.values, n_steps)\n",
        "test_x, test_y = window_generator(test_set.values, n_steps)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR_p5reo69Ak"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, k, heads):\n",
        "    super().__init__()\n",
        "    self.k, self.heads = k, heads\n",
        "\n",
        "    self.tokeys    = nn.Linear(k, k * heads, bias=False)\n",
        "    self.toqueries = nn.Linear(k, k * heads, bias=False)\n",
        "    self.tovalues  = nn.Linear(k, k * heads, bias=False)   \n",
        "    self.unifyheads = nn.Linear(heads * k, k)\n",
        "\n",
        "  def forward(self, x):\n",
        "      b, t, k = x.size()\n",
        "      h = self.heads\n",
        "\n",
        "      queries = self.toqueries(x).view(b, t, h, k)\n",
        "      keys    = self.tokeys(x)   .view(b, t, h, k)\n",
        "      values  = self.tovalues(x) .view(b, t, h, k)\n",
        "\n",
        "\n",
        "      keys = keys.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "      queries = queries.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "      values = values.transpose(1, 2).contiguous().view(b * h, t, k)\n",
        "\n",
        "\n",
        "      queries = queries / (k ** (1/2))\n",
        "      keys    = keys / (k ** (1/2))\n",
        "\n",
        "      # - get dot product of queries and keys, and scale\n",
        "      dot = torch.bmm(queries, keys.transpose(1, 2))\n",
        "      # - dot has size (b*h, t, t) containing raw weights\n",
        "\n",
        "      dot = F.softmax(dot, dim=2) \n",
        "      # - dot now contains row-wise normalized weights\n",
        "\n",
        "      out = torch.bmm(dot, values).view(b, h, t, k)\n",
        "\n",
        "      out = out.transpose(1, 2).contiguous().view(b, t, h * k)\n",
        "      return self.unifyheads(out)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhso9L1pyjYq"
      },
      "source": [
        "results = {}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chw_7ZT7Ae0K"
      },
      "source": [
        "seed = 15\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic=True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr9-ESd98EIf"
      },
      "source": [
        "n_epochs = 30\n",
        "batch_size = 32"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1jO19kg7HLl"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self,feature,target):\n",
        "        self.feature = feature\n",
        "        self.target = target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.feature)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        item = self.feature[idx]\n",
        "        label = self.target[idx]\n",
        "        item = torch.as_tensor(item, dtype = torch.float32)\n",
        "        label = torch.as_tensor(label, dtype = torch.float32)\n",
        "        return item, label\n",
        "\n",
        "train_ds = Dataset(train_x.reshape(train_x.shape[0],train_x.shape[1],1), train_y)\n",
        "valid_ds = Dataset(valid_x.reshape(valid_x.shape[0],valid_x.shape[1],1), valid_y)\n",
        "test_ds = Dataset(test_x.reshape(test_x.shape[0],test_x.shape[1],1), test_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size = 1, shuffle = False)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size = 1, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-wLpTOv7ykO",
        "outputId": "dc6c65b6-bb8a-42c5-eea5-4ca932fe8093"
      },
      "source": [
        "dataset = Dataset(train_x.reshape(train_x.shape[0],train_x.shape[1],1),train_y)\n",
        "print(dataset.__getitem__(0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-8.0500],\n",
            "        [-8.8800],\n",
            "        [-8.8100]]), tensor(-9.0500))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C4KWf6W8CgA"
      },
      "source": [
        "def train_model(model, batch_size, n_epochs):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "        for batch, (data, target) in enumerate(train_loader, 1):\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval() # prep model for evaluation\n",
        "        for data, target in valid_loader:\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'valid_loss: {valid_loss:.5f}')\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "  \n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZg2co41BGEh"
      },
      "source": [
        "def predict (model):\n",
        "  model.eval()  # prepare model for evaluation\n",
        "  sum = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          loss = criterion(output,target)\n",
        "          sum += loss.item()\n",
        "\n",
        "\n",
        "  return (sum/len(test_loader))\n",
        " "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnKecXDvIwGY"
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.Conv1d(3, 64, kernel_size = 1)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)      \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = Net1().to(device)\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9d888Ru8HqT",
        "outputId": "17f2231e-86b3-401e-9d19-91d0b05600d4"
      },
      "source": [
        "model1, train_loss, valid_loss = train_model(model1, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model1) + \"MSELoss: \"] = predict(model1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 31.12170 valid_loss: 41.62337\n",
            "[ 2/30] train_loss: 30.66393 valid_loss: 41.85033\n",
            "[ 3/30] train_loss: 30.10756 valid_loss: 42.04209\n",
            "[ 4/30] train_loss: 29.40699 valid_loss: 42.14557\n",
            "[ 5/30] train_loss: 28.57475 valid_loss: 42.12058\n",
            "[ 6/30] train_loss: 27.59555 valid_loss: 41.92150\n",
            "[ 7/30] train_loss: 26.46112 valid_loss: 41.53049\n",
            "[ 8/30] train_loss: 25.17387 valid_loss: 40.93110\n",
            "[ 9/30] train_loss: 23.73233 valid_loss: 40.10346\n",
            "[10/30] train_loss: 22.14084 valid_loss: 39.05220\n",
            "[11/30] train_loss: 20.40900 valid_loss: 37.78384\n",
            "[12/30] train_loss: 18.55794 valid_loss: 36.28725\n",
            "[13/30] train_loss: 16.63014 valid_loss: 34.59451\n",
            "[14/30] train_loss: 14.68566 valid_loss: 32.81500\n",
            "[15/30] train_loss: 12.77013 valid_loss: 30.96900\n",
            "[16/30] train_loss: 10.93215 valid_loss: 29.08394\n",
            "[17/30] train_loss: 9.21842 valid_loss: 27.21188\n",
            "[18/30] train_loss: 7.67335 valid_loss: 25.34808\n",
            "[19/30] train_loss: 6.32754 valid_loss: 23.44706\n",
            "[20/30] train_loss: 5.19308 valid_loss: 21.61463\n",
            "[21/30] train_loss: 4.27595 valid_loss: 19.89979\n",
            "[22/30] train_loss: 3.56338 valid_loss: 18.27999\n",
            "[23/30] train_loss: 3.03396 valid_loss: 16.78402\n",
            "[24/30] train_loss: 2.65953 valid_loss: 15.42373\n",
            "[25/30] train_loss: 2.40415 valid_loss: 14.20660\n",
            "[26/30] train_loss: 2.23322 valid_loss: 13.13363\n",
            "[27/30] train_loss: 2.11941 valid_loss: 12.19970\n",
            "[28/30] train_loss: 2.04335 valid_loss: 11.38973\n",
            "[29/30] train_loss: 1.99217 valid_loss: 10.68804\n",
            "[30/30] train_loss: 1.95685 valid_loss: 10.07851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcHanaFZKRQf"
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.Conv1d(3, 64, kernel_size = 1),\n",
        "            SelfAttention(1, heads=2)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)     \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model2 = Net2().to(device)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHPV2GAr-VDr",
        "outputId": "3f5463b7-e424-4371-f125-05af350cd5be"
      },
      "source": [
        "model2, train_loss, valid_loss = train_model(model2, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model2) + \"MSELoss: \"] = predict(model2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 31.04564 valid_loss: 41.44039\n",
            "[ 2/30] train_loss: 30.94705 valid_loss: 41.57525\n",
            "[ 3/30] train_loss: 30.83620 valid_loss: 41.71384\n",
            "[ 4/30] train_loss: 30.72433 valid_loss: 41.85569\n",
            "[ 5/30] train_loss: 30.61202 valid_loss: 42.00007\n",
            "[ 6/30] train_loss: 30.49977 valid_loss: 42.14672\n",
            "[ 7/30] train_loss: 30.38777 valid_loss: 42.29556\n",
            "[ 8/30] train_loss: 30.27606 valid_loss: 42.44660\n",
            "[ 9/30] train_loss: 30.16507 valid_loss: 42.59906\n",
            "[10/30] train_loss: 30.05435 valid_loss: 42.75482\n",
            "[11/30] train_loss: 29.94354 valid_loss: 42.91278\n",
            "[12/30] train_loss: 29.83296 valid_loss: 43.07373\n",
            "[13/30] train_loss: 29.72296 valid_loss: 43.23665\n",
            "[14/30] train_loss: 29.61292 valid_loss: 43.40340\n",
            "[15/30] train_loss: 29.50250 valid_loss: 43.57376\n",
            "[16/30] train_loss: 29.39195 valid_loss: 43.74767\n",
            "[17/30] train_loss: 29.28117 valid_loss: 43.92587\n",
            "[18/30] train_loss: 29.16976 valid_loss: 44.10871\n",
            "[19/30] train_loss: 29.05793 valid_loss: 44.29589\n",
            "[20/30] train_loss: 28.94591 valid_loss: 44.48723\n",
            "[21/30] train_loss: 28.83392 valid_loss: 44.68254\n",
            "[22/30] train_loss: 28.72216 valid_loss: 44.88167\n",
            "[23/30] train_loss: 28.61080 valid_loss: 45.08441\n",
            "[24/30] train_loss: 28.50003 valid_loss: 45.29061\n",
            "[25/30] train_loss: 28.38999 valid_loss: 45.50008\n",
            "[26/30] train_loss: 28.28086 valid_loss: 45.71262\n",
            "[27/30] train_loss: 28.17278 valid_loss: 45.92806\n",
            "[28/30] train_loss: 28.06589 valid_loss: 46.14618\n",
            "[29/30] train_loss: 27.96032 valid_loss: 46.36682\n",
            "[30/30] train_loss: 27.85619 valid_loss: 46.58974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvifErQcKSEI"
      },
      "source": [
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net3,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, kernel_size = 1),\n",
        "            SelfAttention(1, heads=2)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)     \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model3 = Net3().to(device)\n",
        "optimizer = torch.optim.Adam(model3.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZzEOl--ZVE",
        "outputId": "345af62f-8538-4e54-8349-172bdcfb11e6"
      },
      "source": [
        "model3, train_loss, valid_loss = train_model(model3, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model3) + \"MSELoss: \"] = predict(model3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 35.78819 valid_loss: 36.99070\n",
            "[ 2/30] train_loss: 32.50687 valid_loss: 34.71549\n",
            "[ 3/30] train_loss: 28.82403 valid_loss: 32.19829\n",
            "[ 4/30] train_loss: 25.35868 valid_loss: 29.50883\n",
            "[ 5/30] train_loss: 22.09552 valid_loss: 26.63399\n",
            "[ 6/30] train_loss: 18.79954 valid_loss: 23.59162\n",
            "[ 7/30] train_loss: 15.50594 valid_loss: 20.36158\n",
            "[ 8/30] train_loss: 12.02423 valid_loss: 17.04525\n",
            "[ 9/30] train_loss: 8.90690 valid_loss: 13.79926\n",
            "[10/30] train_loss: 6.34180 valid_loss: 10.76695\n",
            "[11/30] train_loss: 4.52472 valid_loss: 8.19036\n",
            "[12/30] train_loss: 3.60350 valid_loss: 6.22063\n",
            "[13/30] train_loss: 3.28547 valid_loss: 4.79300\n",
            "[14/30] train_loss: 3.12395 valid_loss: 3.77691\n",
            "[15/30] train_loss: 2.99112 valid_loss: 3.08804\n",
            "[16/30] train_loss: 2.88104 valid_loss: 2.65758\n",
            "[17/30] train_loss: 2.78731 valid_loss: 2.40019\n",
            "[18/30] train_loss: 2.70428 valid_loss: 2.24509\n",
            "[19/30] train_loss: 2.62878 valid_loss: 2.14770\n",
            "[20/30] train_loss: 2.56221 valid_loss: 2.07987\n",
            "[21/30] train_loss: 2.49933 valid_loss: 2.02900\n",
            "[22/30] train_loss: 2.43935 valid_loss: 1.98648\n",
            "[23/30] train_loss: 2.38157 valid_loss: 1.94810\n",
            "[24/30] train_loss: 2.32541 valid_loss: 1.91200\n",
            "[25/30] train_loss: 2.27068 valid_loss: 1.87703\n",
            "[26/30] train_loss: 2.21717 valid_loss: 1.84219\n",
            "[27/30] train_loss: 2.16404 valid_loss: 1.80773\n",
            "[28/30] train_loss: 2.11025 valid_loss: 1.77279\n",
            "[29/30] train_loss: 2.05612 valid_loss: 1.73740\n",
            "[30/30] train_loss: 1.99940 valid_loss: 1.70157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdzUiD59KS18"
      },
      "source": [
        "class Net4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net4,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1),\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)      \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model4 = Net4().to(device)\n",
        "optimizer = torch.optim.Adam(model4.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6uZnPIAZOj"
      },
      "source": [
        "#model4, train_loss, valid_loss = train_model(model4, batch_size, n_epochs)\n",
        "#results[\"Test \" + str(model4) + \"MSELoss: \"] = predict(model4)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LI87g3GKTi-"
      },
      "source": [
        "class Net5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net5,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, kernel_size = 1),\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1),\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)     \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model5 = Net5().to(device)\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90MjYM7RAeG2",
        "outputId": "b0c64b25-f230-445c-948d-f4147d1267d0"
      },
      "source": [
        "model5, train_loss, valid_loss = train_model(model5, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model5) + \"MSELoss: \"] = predict(model5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 31.76264 valid_loss: 40.64207\n",
            "[ 2/30] train_loss: 31.58943 valid_loss: 40.89077\n",
            "[ 3/30] train_loss: 31.34055 valid_loss: 41.20448\n",
            "[ 4/30] train_loss: 31.05451 valid_loss: 41.56246\n",
            "[ 5/30] train_loss: 30.75751 valid_loss: 41.92857\n",
            "[ 6/30] train_loss: 30.46180 valid_loss: 42.33162\n",
            "[ 7/30] train_loss: 30.14571 valid_loss: 42.78951\n",
            "[ 8/30] train_loss: 29.80050 valid_loss: 43.31602\n",
            "[ 9/30] train_loss: 29.43127 valid_loss: 43.90978\n",
            "[10/30] train_loss: 29.04449 valid_loss: 44.56874\n",
            "[11/30] train_loss: 28.65018 valid_loss: 45.28586\n",
            "[12/30] train_loss: 28.25714 valid_loss: 46.05451\n",
            "[13/30] train_loss: 27.87328 valid_loss: 46.86638\n",
            "[14/30] train_loss: 27.50560 valid_loss: 47.71181\n",
            "[15/30] train_loss: 27.15991 valid_loss: 48.58005\n",
            "[16/30] train_loss: 26.84052 valid_loss: 49.45987\n",
            "[17/30] train_loss: 26.54947 valid_loss: 50.32432\n",
            "[18/30] train_loss: 26.29276 valid_loss: 51.21058\n",
            "[19/30] train_loss: 26.06126 valid_loss: 52.06083\n",
            "[20/30] train_loss: 25.86163 valid_loss: 52.88225\n",
            "[21/30] train_loss: 25.68990 valid_loss: 53.66799\n",
            "[22/30] train_loss: 25.54375 valid_loss: 54.41286\n",
            "[23/30] train_loss: 25.42047 valid_loss: 55.11290\n",
            "[24/30] train_loss: 25.31737 valid_loss: 55.76576\n",
            "[25/30] train_loss: 25.23177 valid_loss: 56.37030\n",
            "[26/30] train_loss: 25.16109 valid_loss: 56.92678\n",
            "[27/30] train_loss: 25.10306 valid_loss: 57.43598\n",
            "[28/30] train_loss: 25.05560 valid_loss: 57.89970\n",
            "[29/30] train_loss: 25.01693 valid_loss: 58.31996\n",
            "[30/30] train_loss: 24.98549 valid_loss: 58.69935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeMy-VHYKUUw"
      },
      "source": [
        "class Net6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net6,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, kernel_size = 1),\n",
        "            SelfAttention(1, heads=2),\n",
        "            SelfAttention(1, heads=2)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)     \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model6 = Net6().to(device)\n",
        "optimizer = torch.optim.Adam(model6.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWKtFTFiAhAL",
        "outputId": "fbc1fffb-3ceb-4e2b-9620-4ae6e14c03b6"
      },
      "source": [
        "model6, train_loss, valid_loss = train_model(model6, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model6) + \"MSELoss: \"] = predict(model6)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 29.73259 valid_loss: 41.98274\n",
            "[ 2/30] train_loss: 28.10916 valid_loss: 42.88148\n",
            "[ 3/30] train_loss: 26.36667 valid_loss: 43.23866\n",
            "[ 4/30] train_loss: 24.63957 valid_loss: 43.00058\n",
            "[ 5/30] train_loss: 22.88098 valid_loss: 42.10539\n",
            "[ 6/30] train_loss: 21.03868 valid_loss: 40.70429\n",
            "[ 7/30] train_loss: 19.10867 valid_loss: 38.95942\n",
            "[ 8/30] train_loss: 17.08244 valid_loss: 36.92016\n",
            "[ 9/30] train_loss: 14.99898 valid_loss: 34.64155\n",
            "[10/30] train_loss: 12.91838 valid_loss: 32.27393\n",
            "[11/30] train_loss: 10.91114 valid_loss: 29.86145\n",
            "[12/30] train_loss: 9.04815 valid_loss: 27.47451\n",
            "[13/30] train_loss: 7.42354 valid_loss: 25.15768\n",
            "[14/30] train_loss: 6.08387 valid_loss: 22.88194\n",
            "[15/30] train_loss: 5.06589 valid_loss: 20.74921\n",
            "[16/30] train_loss: 4.35999 valid_loss: 18.84835\n",
            "[17/30] train_loss: 3.90089 valid_loss: 17.17756\n",
            "[18/30] train_loss: 3.60825 valid_loss: 15.73002\n",
            "[19/30] train_loss: 3.40864 valid_loss: 14.49079\n",
            "[20/30] train_loss: 3.26990 valid_loss: 13.41846\n",
            "[21/30] train_loss: 3.15242 valid_loss: 12.42219\n",
            "[22/30] train_loss: 3.05071 valid_loss: 11.57316\n",
            "[23/30] train_loss: 2.96014 valid_loss: 10.80151\n",
            "[24/30] train_loss: 2.87658 valid_loss: 10.11434\n",
            "[25/30] train_loss: 2.79857 valid_loss: 9.50025\n",
            "[26/30] train_loss: 2.72536 valid_loss: 8.92787\n",
            "[27/30] train_loss: 2.65499 valid_loss: 8.41396\n",
            "[28/30] train_loss: 2.59022 valid_loss: 7.93735\n",
            "[29/30] train_loss: 2.52808 valid_loss: 7.51339\n",
            "[30/30] train_loss: 2.46763 valid_loss: 7.13066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQERqVuyKVHB"
      },
      "source": [
        "class Net7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net7,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1),\n",
        "            nn.Conv1d(3, 64, kernel_size = 1),\n",
        "            SelfAttention(1, heads=2),\n",
        "            nn.LayerNorm(1)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.fc1 = nn.Linear(64,50)\n",
        "        self.fc2 = nn.Linear(50,1)      \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model7 = Net7().to(device)\n",
        "optimizer = torch.optim.Adam(model7.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFgSwML9AlW7",
        "outputId": "8ae187aa-8f5b-4489-dc7a-5cded290fb23"
      },
      "source": [
        "model7, train_loss, valid_loss = train_model(model7, batch_size, n_epochs)\n",
        "results[\"Test \" + str(model7) + \"MSELoss: \"] = predict(model7)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1/30] train_loss: 30.60919 valid_loss: 41.97938\n",
            "[ 2/30] train_loss: 30.52351 valid_loss: 42.10328\n",
            "[ 3/30] train_loss: 30.42892 valid_loss: 42.22887\n",
            "[ 4/30] train_loss: 30.33382 valid_loss: 42.35658\n",
            "[ 5/30] train_loss: 30.23944 valid_loss: 42.48397\n",
            "[ 6/30] train_loss: 30.14621 valid_loss: 42.61239\n",
            "[ 7/30] train_loss: 30.05351 valid_loss: 42.74301\n",
            "[ 8/30] train_loss: 29.95987 valid_loss: 42.87750\n",
            "[ 9/30] train_loss: 29.86488 valid_loss: 43.01612\n",
            "[10/30] train_loss: 29.76852 valid_loss: 43.15902\n",
            "[11/30] train_loss: 29.67084 valid_loss: 43.30630\n",
            "[12/30] train_loss: 29.57167 valid_loss: 43.45868\n",
            "[13/30] train_loss: 29.47086 valid_loss: 43.61608\n",
            "[14/30] train_loss: 29.36876 valid_loss: 43.77816\n",
            "[15/30] train_loss: 29.26565 valid_loss: 43.94473\n",
            "[16/30] train_loss: 29.16173 valid_loss: 44.11570\n",
            "[17/30] train_loss: 29.05770 valid_loss: 44.28912\n",
            "[18/30] train_loss: 28.95373 valid_loss: 44.46681\n",
            "[19/30] train_loss: 28.84938 valid_loss: 44.64861\n",
            "[20/30] train_loss: 28.74484 valid_loss: 44.83436\n",
            "[21/30] train_loss: 28.64029 valid_loss: 45.02392\n",
            "[22/30] train_loss: 28.53592 valid_loss: 45.21711\n",
            "[23/30] train_loss: 28.43187 valid_loss: 45.41377\n",
            "[24/30] train_loss: 28.32832 valid_loss: 45.61373\n",
            "[25/30] train_loss: 28.22541 valid_loss: 45.81680\n",
            "[26/30] train_loss: 28.12329 valid_loss: 46.02281\n",
            "[27/30] train_loss: 28.02211 valid_loss: 46.23158\n",
            "[28/30] train_loss: 27.92199 valid_loss: 46.44294\n",
            "[29/30] train_loss: 27.82304 valid_loss: 46.65668\n",
            "[30/30] train_loss: 27.72539 valid_loss: 46.87261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2nW0vmn8xkY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "12f0682d-aba6-4162-aaf1-58775ba35f58"
      },
      "source": [
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.xlim(0, len(train_loss)+1)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnf8kerg84zP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db2f405-fce1-4a35-94ea-e1349e070fd3"
      },
      "source": [
        "i = 0\n",
        "for batch, (x, y) in enumerate(test_loader, 1):\n",
        "  i = i + 1\n",
        "  print(x[0].numpy())\n",
        "  print(y.numpy())\n",
        "  print(model7(x))\n",
        "  if i > 10:\n",
        "    break\n",
        "  print()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-8.01]\n",
            " [-6.62]\n",
            " [-4.85]]\n",
            "[-2.24]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[-6.62]\n",
            " [-4.85]\n",
            " [-2.24]]\n",
            "[0.29]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[-4.85]\n",
            " [-2.24]\n",
            " [ 0.29]]\n",
            "[0.08]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[-2.24]\n",
            " [ 0.29]\n",
            " [ 0.08]]\n",
            "[1.]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[0.29]\n",
            " [0.08]\n",
            " [1.  ]]\n",
            "[1.1]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[0.08]\n",
            " [1.  ]\n",
            " [1.1 ]]\n",
            "[1.31]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[1.  ]\n",
            " [1.1 ]\n",
            " [1.31]]\n",
            "[1.24]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[1.1 ]\n",
            " [1.31]\n",
            " [1.24]]\n",
            "[1.06]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[1.31]\n",
            " [1.24]\n",
            " [1.06]]\n",
            "[1.66]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[1.24]\n",
            " [1.06]\n",
            " [1.66]]\n",
            "[1.52]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n",
            "\n",
            "[[1.06]\n",
            " [1.66]\n",
            " [1.52]]\n",
            "[1.49]\n",
            "tensor([-0.8742], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYALqOfCn8Yi"
      },
      "source": [
        "#nets = [Net1(), Net2(), Net3(), Net4(), Net5(), Net6(), Net7()]\n",
        "\n",
        "#for n in nets:\n",
        "  #model = n.to(device)\n",
        "  #print(model)\n",
        "  #model, train_loss, valid_loss = train_model(model, batch_size, n_epochs)\n",
        "  #results[\"Test \" + str(n) + \"MSELoss: \"] = predict(model)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czARonOgDmbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c663442e-b90d-414d-bf3e-eae777aa06a8"
      },
      "source": [
        "\n",
        "\n",
        "for x in results:\n",
        "  print(x,':',results[x])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Net1(\n",
            "  (layer1): Sequential(\n",
            "    (0): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 4.961216407561811\n",
            "Test Net2(\n",
            "  (layer1): Sequential(\n",
            "    (0): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "    (2): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 27.031678588772834\n",
            "Test Net3(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "    (1): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 1.6881438445518337\n",
            "Test Net5(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "    (1): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (2): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
            "    (3): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (4): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 39.13314695039744\n",
            "Test Net6(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "    (1): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (2): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 3.807741028622734\n",
            "Test Net7(\n",
            "  (layer1): Sequential(\n",
            "    (0): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (1): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
            "    (2): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
            "    (3): SelfAttention(\n",
            "      (tokeys): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (toqueries): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (tovalues): Linear(in_features=1, out_features=2, bias=False)\n",
            "      (unifyheads): Linear(in_features=2, out_features=1, bias=True)\n",
            "    )\n",
            "    (4): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (fc1): Linear(in_features=64, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
            ")MSELoss:  : 27.314327739195157\n"
          ]
        }
      ]
    }
  ]
}